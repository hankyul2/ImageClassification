# 1. load data
data:
  class_path: src.data.cifar.CIFAR10_DataModule
  init_args:
    dataset_name: cifar10
    batch_size: 16
    num_workers: 4
    size:
    - 224
    - 224
    data_root: data
    valid_ratio: 0.1

# 2. define model (define other backbone)
model:
  class_path: src.system.finetune.Finetune
  init_args:
    backbone_init:
      model_name: "resnet18"
      pretrained: true
    # 3. prepare train tools (optimizer, learning rate scheduler)
    optimizer_init:
      class_path: torch.optim.SGD
      init_args:
        lr: 0.03
        momentum: 0.95
        weight_decay: 0.0005

    lr_scheduler_init:
      class_path: src.lr_schedulers.CosineLR
      init_args:
        max_epochs: 0
        num_step: 0
        warmup_epoch: 1

# 4. train
seed_everything: null
trainer:
  # 4-1. gpu devices
  accelerator: null
  gpus: "5,"
  amp_backend: native

  # 4-2. train setting
  check_val_every_n_epoch: 1
  val_check_interval: 1.0
  max_epochs: 1

  # 4-3. logger & callbacks
  logger: true
  log_every_n_steps: 50
  callbacks: null
  checkpoint_callback: true
  resume_from_checkpoint: null

  # 4-4. hyper param tuning
  auto_lr_find: false
  auto_scale_batch_size: false

  # 4-5. for debugging
  fast_dev_run: false
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  limit_predict_batches: 1.0

  # 4-6. etc
  profiler: null
  precision: 32
  multiple_trainloader_mode: max_size_cycle
